{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd46982b-6f20-4600-8ed7-d69f57f4b564",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear directories if they exist\n",
    "import shutil\n",
    "try:\n",
    "    shutil.rmtree(\"data/train\")\n",
    "    shutil.rmtree(\"data/test\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaf55c51-66ba-4135-99f5-a48aca898069",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create train and test directories\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "Path(\"data/train/damage\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"data/train/no_damage\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "Path(\"data/test/damage\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"data/test/no_damage\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f89f3ac-7777-4e35-9362-cd38284dac9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get images from OS\n",
    "all_damage_paths = os.listdir('data/damage')\n",
    "all_no_damage_paths = os.listdir('data/no_damage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7ef65dd-aeb4-4dec-85f5-10c0519f2996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of damage images 14170\n",
      "amount of non damage images 7152\n"
     ]
    }
   ],
   "source": [
    "print(\"amount of damage images\", len(all_damage_paths))\n",
    "print(\"amount of non damage images\", len(all_no_damage_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aea1e67-d3ce-493f-bd25-5a01375c37ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5158/1449807412.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a DataFrame with a 'Category' column using the counts from arrays\n",
    "df = pd.DataFrame({\n",
    "    'Category': ([\"damage\"] * len(all_damage_paths)) + ([\"no_damage\"] * len(all_no_damage_paths))\n",
    "})\n",
    "\n",
    "# Plot the countplot\n",
    "sns.countplot(x='Category', data=df)\n",
    "plt.title('Count of Images by Category')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d996b0a-b6b7-40d0-9656-094fd4164fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train damage image count:  11336\n",
      "test damage image count:  2834\n",
      "len of overlap:  0\n",
      "train no_damage image count:  5721\n",
      "test no_damage image count:  1431\n",
      "len of overlap:  0\n"
     ]
    }
   ],
   "source": [
    "# populate train and test variables\n",
    "import random\n",
    "\n",
    "train_damage_paths = random.sample(all_damage_paths, int(len(all_damage_paths)*0.8))\n",
    "print(\"train damage image count: \", len(train_damage_paths))\n",
    "test_damage_paths = [ p for p in all_damage_paths if p not in train_damage_paths]\n",
    "print(\"test damage image count: \", len(test_damage_paths))\n",
    "# ensure no overlap:\n",
    "overlap = [p for p in train_damage_paths if p in test_damage_paths]\n",
    "print(\"len of overlap: \", len(overlap))\n",
    "\n",
    "train_no_damage_paths = random.sample(all_no_damage_paths, int(len(all_no_damage_paths)*0.8))\n",
    "print(\"train no_damage image count: \", len(train_no_damage_paths))\n",
    "test_no_damage_paths = [ p for p in all_no_damage_paths if p not in train_no_damage_paths]\n",
    "print(\"test no_damage image count: \", len(test_no_damage_paths))\n",
    "# ensure no overlap:\n",
    "overlap = [p for p in train_no_damage_paths if p in test_no_damage_paths]\n",
    "print(\"len of overlap: \", len(overlap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc770954-9949-4d08-a357-5a6521b4eccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in train/damage:  11336\n",
      "Files in train/no_damage:  5721\n",
      "Files in test/damage:  2834\n",
      "Files in test/no_damage:  1431\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Copy the \"damage\" images:\n",
    "for p in train_damage_paths:\n",
    "    if p != \".ipynb_checkpoints\":\n",
    "        shutil.copyfile(os.path.join('data', 'damage', p),\n",
    "                        os.path.join('data', 'train', 'damage', p))\n",
    "\n",
    "for p in test_damage_paths:\n",
    "    if p != \".ipynb_checkpoints\":\n",
    "        shutil.copyfile(os.path.join('data', 'damage', p),\n",
    "                        os.path.join('data', 'test', 'damage', p))\n",
    "\n",
    "# Copy the \"no_damage\" images:\n",
    "for p in train_no_damage_paths:\n",
    "    if p != \".ipynb_checkpoints\":\n",
    "        shutil.copyfile(os.path.join('data', 'no_damage', p),\n",
    "                        os.path.join('data', 'train', 'no_damage', p))\n",
    "\n",
    "for p in test_no_damage_paths:\n",
    "    if p != \".ipynb_checkpoints\":\n",
    "        shutil.copyfile(os.path.join('data', 'no_damage', p),\n",
    "                        os.path.join('data', 'test', 'no_damage', p))\n",
    "\n",
    "# Check counts:\n",
    "print(\"Files in train/damage: \", len(os.listdir(os.path.join(\"data\", \"train\", \"damage\"))))\n",
    "print(\"Files in train/no_damage: \", len(os.listdir(os.path.join(\"data\", \"train\", \"no_damage\"))))\n",
    "print(\"Files in test/damage: \", len(os.listdir(os.path.join(\"data\", \"test\", \"damage\"))))\n",
    "print(\"Files in test/no_damage: \", len(os.listdir(os.path.join(\"data\", \"test\", \"no_damage\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19f228c8-2e6d-4eea-b15c-29df671f70b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 05:52:45.307777: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-10 05:52:45.369382: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-10 05:52:45.369456: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-10 05:52:45.374435: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-10 05:52:45.392120: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-10 05:52:45.393967: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-10 05:52:46.577776: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17057 files belonging to 2 classes.\n",
      "Using 13646 files for training.\n",
      "Using 3411 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# import needed classes and functions\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "\n",
    "# path to training data\n",
    "train_data_dir = 'data/train'\n",
    "\n",
    "# controls the size of the \"batches\" of images streamed when accessing the datasets.\n",
    "# this is useful to control the memory usage with very large datasets\n",
    "batch_size = 32\n",
    "\n",
    "# target image size\n",
    "img_height = 150\n",
    "img_width = 150\n",
    "\n",
    "# note that the subset parameter can take values of \"training\", \"validation\", or \"both\";\n",
    "# the value dictates which dataset is returned (we want both)\n",
    "train_ds, val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "# rescale instance\n",
    "rescale = Rescaling(scale=1.0/255)\n",
    "\n",
    "# apply the rescale to the train and validation sets\n",
    "train_rescale_ds = train_ds.map(lambda image,label:(rescale(image),label))\n",
    "val_rescale_ds = val_ds.map(lambda image,label:(rescale(image),label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38a1f4a6-b038-4909-a3a8-638a40d25465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4265 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# path to test data\n",
    "test_data_dir = 'data/test'\n",
    "\n",
    "# we do not set subset=both here because we do not want the test set split\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_data_dir,\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    ")\n",
    "\n",
    "# approach 1: manually rescale data --\n",
    "rescale = Rescaling(scale=1.0/255)\n",
    "test_rescale_ds = test_ds.map(lambda image,label:(rescale(image),label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff687874-858c-4a59-8650-b89bcd35ad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert data to numpy array for ANN use \n",
    "import numpy as np\n",
    "\n",
    "def dataset_to_numpy(dataset):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # Iterate over the dataset batches\n",
    "    for batch_images, batch_labels in dataset:\n",
    "        # Convert each batch to a NumPy array and collect in lists\n",
    "        images.append(batch_images.numpy())\n",
    "        labels.append(batch_labels.numpy())\n",
    "    \n",
    "    # Concatenate the list into one numpy array along the batch axis\n",
    "    images = np.concatenate(images, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    return images, labels\n",
    "\n",
    "X_train, y_train = dataset_to_numpy(train_rescale_ds)\n",
    "X_val, y_val = dataset_to_numpy(val_rescale_ds)\n",
    "X_test, y_test = dataset_to_numpy(test_rescale_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b661c93a-5bf2-48f7-8cfc-cc7e3408c911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of samples and the image shape (height, width, channels)\n",
    "num_train_samples = X_train.shape[0]\n",
    "num_val_samples = X_val.shape[0]\n",
    "num_test_samples = X_test.shape[0]\n",
    "image_shape = img_height*img_width*3\n",
    "\n",
    "# Flatten the images if needed (e.g., for an ANN)\n",
    "X_train_flat = X_train.reshape(num_train_samples, -1)\n",
    "X_val_flat = X_val.reshape(num_val_samples, -1)\n",
    "X_test_flat = X_test.reshape(num_test_samples, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43ed5d11-abe7-4a92-afe1-5b96dcead4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create default ann \n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "image_size=img_height*img_width*3\n",
    "\n",
    "ANN = Sequential()\n",
    "ANN.add(Dense(784, activation='relu',input_shape=(image_size,)))\n",
    "\n",
    "ANN.add(Dense(128, activation='relu'))\n",
    "\n",
    "ANN.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34278ece-793c-4b28-b84a-56ea67c029d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 05:53:04.188621: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 3684420000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "427/427 [==============================] - 141s 329ms/step - loss: 1.5954 - accuracy: 0.6315 - val_loss: 0.6489 - val_accuracy: 0.6884\n",
      "Epoch 2/40\n",
      "427/427 [==============================] - 137s 321ms/step - loss: 0.6138 - accuracy: 0.6930 - val_loss: 0.5724 - val_accuracy: 0.7016\n",
      "Epoch 3/40\n",
      "427/427 [==============================] - 136s 318ms/step - loss: 0.5624 - accuracy: 0.7237 - val_loss: 0.5333 - val_accuracy: 0.7573\n",
      "Epoch 5/40\n",
      "427/427 [==============================] - 136s 319ms/step - loss: 0.5762 - accuracy: 0.7072 - val_loss: 0.5994 - val_accuracy: 0.7405\n",
      "Epoch 6/40\n",
      "427/427 [==============================] - 138s 324ms/step - loss: 0.5916 - accuracy: 0.6779 - val_loss: 0.6536 - val_accuracy: 0.6681\n",
      "Epoch 7/40\n",
      "427/427 [==============================] - 137s 322ms/step - loss: 0.5907 - accuracy: 0.6646 - val_loss: 0.5986 - val_accuracy: 0.7282\n",
      "Epoch 8/40\n",
      "427/427 [==============================] - 138s 323ms/step - loss: 0.5797 - accuracy: 0.7072 - val_loss: 0.5570 - val_accuracy: 0.7353\n",
      "Epoch 10/40\n",
      "427/427 [==============================] - 137s 322ms/step - loss: 0.5741 - accuracy: 0.7122 - val_loss: 0.5609 - val_accuracy: 0.7235\n",
      "Epoch 11/40\n",
      "427/427 [==============================] - 137s 321ms/step - loss: 0.5816 - accuracy: 0.7108 - val_loss: 0.6977 - val_accuracy: 0.5535\n",
      "Epoch 12/40\n",
      "427/427 [==============================] - 138s 324ms/step - loss: 0.5857 - accuracy: 0.7036 - val_loss: 0.5546 - val_accuracy: 0.7403\n",
      "Epoch 13/40\n",
      "427/427 [==============================] - 138s 324ms/step - loss: 0.5659 - accuracy: 0.7288 - val_loss: 0.5505 - val_accuracy: 0.7405\n",
      "Epoch 14/40\n",
      "427/427 [==============================] - 138s 322ms/step - loss: 0.5737 - accuracy: 0.7173 - val_loss: 0.7363 - val_accuracy: 0.4248\n",
      "Epoch 15/40\n",
      "427/427 [==============================] - 137s 320ms/step - loss: 0.5680 - accuracy: 0.7188 - val_loss: 0.5702 - val_accuracy: 0.6998\n",
      "Epoch 16/40\n",
      "427/427 [==============================] - 138s 322ms/step - loss: 0.5659 - accuracy: 0.7241 - val_loss: 0.5489 - val_accuracy: 0.7464\n",
      "Epoch 17/40\n",
      "427/427 [==============================] - 138s 322ms/step - loss: 0.5745 - accuracy: 0.7127 - val_loss: 0.5615 - val_accuracy: 0.7259\n",
      "Epoch 18/40\n",
      "427/427 [==============================] - 138s 324ms/step - loss: 0.5746 - accuracy: 0.7026 - val_loss: 0.6265 - val_accuracy: 0.5708\n",
      "Epoch 19/40\n",
      "427/427 [==============================] - 138s 324ms/step - loss: 0.5925 - accuracy: 0.6653 - val_loss: 0.5660 - val_accuracy: 0.6681\n",
      "Epoch 20/40\n",
      "427/427 [==============================] - 138s 324ms/step - loss: 0.5696 - accuracy: 0.7105 - val_loss: 0.5511 - val_accuracy: 0.7441\n",
      "Epoch 21/40\n",
      "424/427 [============================>.] - ETA: 0s - loss: 0.5670 - accuracy: 0.7214"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "427/427 [==============================] - 139s 326ms/step - loss: 0.5596 - accuracy: 0.7303 - val_loss: 0.5853 - val_accuracy: 0.6925\n",
      "Epoch 23/40\n",
      "427/427 [==============================] - 140s 327ms/step - loss: 0.5621 - accuracy: 0.7275 - val_loss: 0.5665 - val_accuracy: 0.7068\n",
      "Epoch 24/40\n",
      "427/427 [==============================] - 139s 326ms/step - loss: 0.5713 - accuracy: 0.7190 - val_loss: 0.5707 - val_accuracy: 0.6992\n",
      "Epoch 25/40\n",
      "427/427 [==============================] - 138s 324ms/step - loss: 0.5955 - accuracy: 0.6790 - val_loss: 0.5721 - val_accuracy: 0.7018\n",
      "Epoch 26/40\n",
      "427/427 [==============================] - 138s 324ms/step - loss: 0.5746 - accuracy: 0.6998 - val_loss: 0.6232 - val_accuracy: 0.5705\n",
      "Epoch 27/40\n",
      "427/427 [==============================] - 138s 323ms/step - loss: 0.5802 - accuracy: 0.7032 - val_loss: 0.5854 - val_accuracy: 0.6913\n",
      "Epoch 28/40\n",
      "427/427 [==============================] - 140s 328ms/step - loss: 0.5610 - accuracy: 0.7264 - val_loss: 0.5526 - val_accuracy: 0.7414\n",
      "Epoch 30/40\n",
      "427/427 [==============================] - 138s 323ms/step - loss: 0.5710 - accuracy: 0.7152 - val_loss: 0.5629 - val_accuracy: 0.7183\n",
      "Epoch 31/40\n",
      "427/427 [==============================] - 138s 324ms/step - loss: 0.5706 - accuracy: 0.7130 - val_loss: 0.5503 - val_accuracy: 0.7326\n",
      "Epoch 32/40\n",
      "427/427 [==============================] - 138s 323ms/step - loss: 0.5866 - accuracy: 0.6742 - val_loss: 0.5691 - val_accuracy: 0.7112\n",
      "Epoch 33/40\n",
      "427/427 [==============================] - 138s 324ms/step - loss: 0.5639 - accuracy: 0.7273 - val_loss: 0.5974 - val_accuracy: 0.6752\n",
      "Epoch 34/40\n",
      "427/427 [==============================] - 139s 325ms/step - loss: 0.5728 - accuracy: 0.7091 - val_loss: 0.5424 - val_accuracy: 0.7476\n",
      "Epoch 35/40\n",
      "427/427 [==============================] - 140s 329ms/step - loss: 0.5593 - accuracy: 0.7341 - val_loss: 0.5985 - val_accuracy: 0.7042\n",
      "Epoch 36/40\n",
      " 25/427 [>.............................] - ETA: 2:07 - loss: 0.5663 - accuracy: 0.7337"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "427/427 [==============================] - 140s 328ms/step - loss: 0.5604 - accuracy: 0.7295 - val_loss: 0.5672 - val_accuracy: 0.7279\n",
      "Epoch 37/40\n",
      "427/427 [==============================] - 139s 325ms/step - loss: 0.5651 - accuracy: 0.7113 - val_loss: 0.5472 - val_accuracy: 0.7449\n",
      "Epoch 38/40\n",
      "427/427 [==============================] - 139s 326ms/step - loss: 0.5543 - accuracy: 0.7338 - val_loss: 0.5529 - val_accuracy: 0.7303\n",
      "Epoch 39/40\n",
      "427/427 [==============================] - 140s 327ms/step - loss: 0.5572 - accuracy: 0.7371 - val_loss: 0.6153 - val_accuracy: 0.6760\n",
      "Epoch 40/40\n",
      "427/427 [==============================] - 139s 327ms/step - loss: 0.5651 - accuracy: 0.7208 - val_loss: 0.5767 - val_accuracy: 0.7268\n"
     ]
    }
   ],
   "source": [
    "# Compile your model\n",
    "ANN.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model using the flattened training data\n",
    "history = ANN.fit(\n",
    "    X_train_flat, y_train,\n",
    "    batch_size=32,\n",
    "    epochs=40,\n",
    "    validation_data=(X_val_flat, y_val)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e354316d-8811-4298-a9c5-b3cf3bf248db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 6s 44ms/step - loss: 0.5849 - accuracy: 0.7280\n",
      "Loss on test: 0.5849300622940063\n",
      "Accuracy on test: 0.7280187606811523\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = ANN.evaluate(X_test_flat, y_test)\n",
    "print(f\"Loss on test: {test_loss}\")\n",
    "print(f\"Accuracy on test: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edb3528c-777b-4915-8e5c-0256da152db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 6)       168       \n",
      "                                                                 \n",
      " average_pooling2d (Average  (None, 74, 74, 6)         0         \n",
      " Pooling2D)                                                      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 16)        880       \n",
      "                                                                 \n",
      " average_pooling2d_1 (Avera  (None, 36, 36, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 20736)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 120)               2488440   \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499822 (9.54 MB)\n",
      "Trainable params: 2499822 (9.54 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#create lenet5 cnn\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import pandas as pd\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "model_lenet5 = models.Sequential()\n",
    "\n",
    "# Layer 1: Convolutional layer with 6 filters of size 3x3, followed by average pooling\n",
    "model_lenet5.add(layers.Conv2D(6, kernel_size=(3, 3), activation='relu', input_shape=(150,150,3)))\n",
    "model_lenet5.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 2: Convolutional layer with 16 filters of size 3x3, followed by average pooling\n",
    "model_lenet5.add(layers.Conv2D(16, kernel_size=(3, 3), activation='relu'))\n",
    "model_lenet5.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the feature maps to feed into fully connected layers\n",
    "model_lenet5.add(layers.Flatten())\n",
    "\n",
    "# Layer 3: Fully connected layer with 120 neurons\n",
    "model_lenet5.add(layers.Dense(120, activation='relu'))\n",
    "\n",
    "# Layer 4: Fully connected layer with 84 neurons\n",
    "model_lenet5.add(layers.Dense(84, activation='relu'))\n",
    "\n",
    "# Output layer: Fully connected layer with num_classes neurons (e.g., 3 )\n",
    "model_lenet5.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model_lenet5.compile(optimizer=optimizers.RMSprop(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Generating the summary of the model\n",
    "model_lenet5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fed5d7-a1a8-4f07-a296-ac01b7014b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "427/427 [==============================] - 33s 75ms/step - loss: 0.6078 - accuracy: 0.6999 - val_loss: 0.5195 - val_accuracy: 0.8080\n",
      "Epoch 2/40\n",
      "427/427 [==============================] - 32s 74ms/step - loss: 0.4840 - accuracy: 0.7951 - val_loss: 0.4097 - val_accuracy: 0.8508\n",
      "Epoch 3/40\n",
      "427/427 [==============================] - 31s 73ms/step - loss: 0.4143 - accuracy: 0.8350 - val_loss: 0.4342 - val_accuracy: 0.8308\n",
      "Epoch 4/40\n",
      "427/427 [==============================] - 32s 74ms/step - loss: 0.3793 - accuracy: 0.8539 - val_loss: 0.5055 - val_accuracy: 0.7704\n",
      "Epoch 5/40\n",
      "427/427 [==============================] - 31s 72ms/step - loss: 0.3610 - accuracy: 0.8598 - val_loss: 0.4279 - val_accuracy: 0.8197\n",
      "Epoch 6/40\n",
      "427/427 [==============================] - 30s 69ms/step - loss: 0.3405 - accuracy: 0.8696 - val_loss: 0.4506 - val_accuracy: 0.8001\n",
      "Epoch 7/40\n",
      "427/427 [==============================] - 30s 70ms/step - loss: 0.3239 - accuracy: 0.8764 - val_loss: 0.3820 - val_accuracy: 0.8432\n",
      "Epoch 8/40\n",
      "427/427 [==============================] - 31s 71ms/step - loss: 0.3091 - accuracy: 0.8836 - val_loss: 0.3308 - val_accuracy: 0.8640\n",
      "Epoch 9/40\n",
      " 67/427 [===>..........................] - ETA: 23s - loss: 0.3005 - accuracy: 0.8871Epoch 13/40\n",
      "427/427 [==============================] - 31s 73ms/step - loss: 0.2383 - accuracy: 0.9069 - val_loss: 0.2545 - val_accuracy: 0.8959\n",
      "Epoch 14/40\n",
      "427/427 [==============================] - 31s 72ms/step - loss: 0.2260 - accuracy: 0.9119 - val_loss: 0.2396 - val_accuracy: 0.9003\n",
      "Epoch 15/40\n",
      "427/427 [==============================] - 31s 73ms/step - loss: 0.2124 - accuracy: 0.9174 - val_loss: 0.2329 - val_accuracy: 0.9021\n",
      "Epoch 16/40\n",
      "427/427 [==============================] - 31s 73ms/step - loss: 0.2024 - accuracy: 0.9204 - val_loss: 0.2298 - val_accuracy: 0.9038\n",
      "Epoch 17/40\n",
      "427/427 [==============================] - 31s 73ms/step - loss: 0.1896 - accuracy: 0.9275 - val_loss: 0.2730 - val_accuracy: 0.8889\n",
      "Epoch 18/40\n",
      "427/427 [==============================] - 31s 73ms/step - loss: 0.1819 - accuracy: 0.9291 - val_loss: 0.2298 - val_accuracy: 0.9003\n",
      "Epoch 19/40\n",
      "427/427 [==============================] - 31s 72ms/step - loss: 0.1696 - accuracy: 0.9329 - val_loss: 0.2161 - val_accuracy: 0.9056\n",
      "Epoch 20/40\n",
      "  3/427 [..............................] - ETA: 29s - loss: 0.1160 - accuracy: 0.9688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit the model from image generator\n",
    "history = model_lenet5.fit(\n",
    "            train_rescale_ds,\n",
    "            batch_size=32,\n",
    "            epochs=40,\n",
    "            validation_data=val_rescale_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e91341b8-2640-41c6-b983-4858c7edb5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on test: 0.3093070089817047\n",
      "Accuracy on test: 0.9193434715270996\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model_lenet5.evaluate(test_rescale_ds, verbose=0)\n",
    "print(f\"Loss on test: {test_loss}\")\n",
    "print(f\"Accuracy on test: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86675b64-e2b6-4ff9-a252-7bac49453595",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create alternate lenet5 cnn \n",
    "from keras import layers\n",
    "from keras import models\n",
    "import pandas as pd\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "model_alternateLe = models.Sequential()\n",
    "\n",
    "# Layer 1: Convolutional layer with 32 filters of size 3x3, followed by average pooling\n",
    "model_alternateLe.add(layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(150,150,3)))\n",
    "model_alternateLe.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 2: Convolutional layer with 64 filters of size 3x3, followed by average pooling\n",
    "model_alternateLe.add(layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model_alternateLe.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 3: Convolutional layer with 128 filters of size 3x3, followed by average pooling\n",
    "model_alternateLe.add(layers.Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model_alternateLe.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 4: Convolutional layer with 128 filters of size 3x3, followed by average pooling\n",
    "model_alternateLe.add(layers.Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model_alternateLe.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the feature maps to feed into fully connected layers\n",
    "model_alternateLe.add(layers.Flatten())\n",
    "\n",
    "model_alternateLe.add(layers.Dropout(0.2))\n",
    "\n",
    "\n",
    "# Layer 3: Fully connected layer with 512 neurons\n",
    "model_alternateLe.add(layers.Dense(512, activation='relu'))\n",
    "\n",
    "# Output layer: Fully connected layer with num_classes neurons (e.g., 3 )\n",
    "#this differs from the paper because we have two output classes, not one \n",
    "model_alternateLe.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model_alternateLe.compile(optimizer=optimizers.RMSprop(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Generating the summary of the model\n",
    "model_alternateLe.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6da8251c-c1bb-410b-ada2-8180a5db32a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "427/427 [==============================] - 145s 338ms/step - loss: 0.6010 - accuracy: 0.6924 - val_loss: 0.5736 - val_accuracy: 0.7297\n",
      "Epoch 2/40\n",
      "427/427 [==============================] - 147s 345ms/step - loss: 0.4569 - accuracy: 0.7975 - val_loss: 0.4111 - val_accuracy: 0.8094\n",
      "Epoch 3/40\n",
      "427/427 [==============================] - 147s 345ms/step - loss: 0.3767 - accuracy: 0.8478 - val_loss: 0.3233 - val_accuracy: 0.8769\n",
      "Epoch 4/40\n",
      "427/427 [==============================] - 152s 355ms/step - loss: 0.2808 - accuracy: 0.8899 - val_loss: 0.2455 - val_accuracy: 0.9035\n",
      "Epoch 6/40\n",
      "427/427 [==============================] - 153s 358ms/step - loss: 0.1773 - accuracy: 0.9313 - val_loss: 0.2040 - val_accuracy: 0.9197\n",
      "Epoch 9/40\n",
      "427/427 [==============================] - 151s 354ms/step - loss: 0.1634 - accuracy: 0.9355 - val_loss: 0.1711 - val_accuracy: 0.9340\n",
      "Epoch 10/40\n",
      "427/427 [==============================] - 152s 356ms/step - loss: 0.1501 - accuracy: 0.9403 - val_loss: 0.2007 - val_accuracy: 0.9167\n",
      "Epoch 11/40\n",
      "427/427 [==============================] - 152s 357ms/step - loss: 0.1421 - accuracy: 0.9431 - val_loss: 0.1485 - val_accuracy: 0.9396\n",
      "Epoch 12/40\n",
      "427/427 [==============================] - 153s 358ms/step - loss: 0.1339 - accuracy: 0.9478 - val_loss: 0.1262 - val_accuracy: 0.9466\n",
      "Epoch 13/40\n",
      "427/427 [==============================] - 153s 359ms/step - loss: 0.1184 - accuracy: 0.9535 - val_loss: 0.1417 - val_accuracy: 0.9446\n",
      "Epoch 15/40\n",
      "427/427 [==============================] - 153s 358ms/step - loss: 0.1160 - accuracy: 0.9574 - val_loss: 0.1471 - val_accuracy: 0.9437\n",
      "Epoch 16/40\n",
      "427/427 [==============================] - 153s 357ms/step - loss: 0.1078 - accuracy: 0.9581 - val_loss: 0.1103 - val_accuracy: 0.9540\n",
      "Epoch 17/40\n",
      "427/427 [==============================] - 152s 357ms/step - loss: 0.1061 - accuracy: 0.9595 - val_loss: 0.1032 - val_accuracy: 0.9563\n",
      "Epoch 18/40\n",
      "427/427 [==============================] - 152s 356ms/step - loss: 0.0991 - accuracy: 0.9617 - val_loss: 0.1190 - val_accuracy: 0.9519\n",
      "Epoch 19/40\n",
      "427/427 [==============================] - 153s 359ms/step - loss: 0.0952 - accuracy: 0.9622 - val_loss: 0.1698 - val_accuracy: 0.9349\n",
      "Epoch 20/40\n",
      "427/427 [==============================] - 152s 356ms/step - loss: 0.0900 - accuracy: 0.9662 - val_loss: 0.1115 - val_accuracy: 0.9584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit the model from image generator\n",
    "history = model_alternateLe.fit(\n",
    "            train_rescale_ds,\n",
    "            batch_size=32,\n",
    "            epochs=40,\n",
    "            validation_data=val_rescale_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95f8ad08-ff32-4ee3-85c1-e19a37b3372f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on test: 0.09453023225069046\n",
      "Accuracy on test: 0.9706916809082031\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model_alternateLe.evaluate(test_rescale_ds, verbose=0)\n",
    "print(f\"Loss on test: {test_loss}\")\n",
    "print(f\"Accuracy on test: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2fe601d6-3b27-484e-a140-2acd58080e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_3 (Sequential)   (None, 150, 150, 3)       0         \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               1048704   \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 128)               512       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15772546 (60.17 MB)\n",
      "Trainable params: 8136898 (31.04 MB)\n",
      "Non-trainable params: 7635648 (29.13 MB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "427/427 [==============================] - 621s 1s/step - loss: 0.5434 - accuracy: 0.7837 - val_loss: 0.3065 - val_accuracy: 0.8804\n",
      "Epoch 2/40\n",
      "427/427 [==============================] - 620s 1s/step - loss: 0.3704 - accuracy: 0.8608 - val_loss: 0.2635 - val_accuracy: 0.8991\n",
      "Epoch 3/40\n",
      "427/427 [==============================] - 621s 1s/step - loss: 0.2898 - accuracy: 0.8934 - val_loss: 0.2695 - val_accuracy: 0.9074\n",
      "Epoch 5/40\n",
      "427/427 [==============================] - 617s 1s/step - loss: 0.2420 - accuracy: 0.9091 - val_loss: 0.1976 - val_accuracy: 0.9291\n",
      "Epoch 7/40\n",
      "427/427 [==============================] - 618s 1s/step - loss: 0.2188 - accuracy: 0.9190 - val_loss: 0.2487 - val_accuracy: 0.9132\n",
      "Epoch 8/40\n",
      "427/427 [==============================] - 656s 2s/step - loss: 0.2067 - accuracy: 0.9234 - val_loss: 0.1510 - val_accuracy: 0.9384\n",
      "Epoch 9/40\n",
      "427/427 [==============================] - 655s 2s/step - loss: 0.1978 - accuracy: 0.9280 - val_loss: 0.1406 - val_accuracy: 0.9422\n",
      "Epoch 10/40\n",
      "427/427 [==============================] - 616s 1s/step - loss: 0.1886 - accuracy: 0.9320 - val_loss: 0.1417 - val_accuracy: 0.9414\n",
      "Epoch 11/40\n",
      "427/427 [==============================] - 620s 1s/step - loss: 0.1721 - accuracy: 0.9367 - val_loss: 0.1339 - val_accuracy: 0.9475\n",
      "Epoch 12/40\n",
      "427/427 [==============================] - 617s 1s/step - loss: 0.1641 - accuracy: 0.9412 - val_loss: 0.1388 - val_accuracy: 0.9425\n",
      "Epoch 13/40\n",
      "427/427 [==============================] - 620s 1s/step - loss: 0.1586 - accuracy: 0.9420 - val_loss: 0.1293 - val_accuracy: 0.9502\n",
      "Epoch 14/40\n",
      "427/427 [==============================] - 622s 1s/step - loss: 0.1575 - accuracy: 0.9440 - val_loss: 0.1142 - val_accuracy: 0.9549\n",
      "Epoch 15/40\n",
      "427/427 [==============================] - 621s 1s/step - loss: 0.1439 - accuracy: 0.9474 - val_loss: 0.1490 - val_accuracy: 0.9464\n",
      "Epoch 16/40\n",
      "427/427 [==============================] - 620s 1s/step - loss: 0.1358 - accuracy: 0.9524 - val_loss: 0.1242 - val_accuracy: 0.9510\n",
      "Epoch 17/40\n",
      "427/427 [==============================] - 620s 1s/step - loss: 0.1349 - accuracy: 0.9508 - val_loss: 0.1786 - val_accuracy: 0.9264\n",
      "Epoch 18/40\n",
      "427/427 [==============================] - 615s 1s/step - loss: 0.1234 - accuracy: 0.9546 - val_loss: 0.1086 - val_accuracy: 0.9613\n",
      "Epoch 19/40\n",
      "427/427 [==============================] - 615s 1s/step - loss: 0.1219 - accuracy: 0.9565 - val_loss: 0.2141 - val_accuracy: 0.9115\n",
      "Epoch 20/40\n",
      "427/427 [==============================] - 616s 1s/step - loss: 0.1167 - accuracy: 0.9587 - val_loss: 0.1507 - val_accuracy: 0.9422\n",
      "Epoch 21/40\n",
      "427/427 [==============================] - 615s 1s/step - loss: 0.1142 - accuracy: 0.9586 - val_loss: 0.1121 - val_accuracy: 0.9590\n",
      "Epoch 22/40\n",
      "427/427 [==============================] - 618s 1s/step - loss: 0.1089 - accuracy: 0.9609 - val_loss: 0.1117 - val_accuracy: 0.9619\n",
      "Epoch 23/40\n",
      "427/427 [==============================] - 618s 1s/step - loss: 0.1071 - accuracy: 0.9617 - val_loss: 0.1317 - val_accuracy: 0.9505\n",
      "Epoch 24/40\n",
      "427/427 [==============================] - 619s 1s/step - loss: 0.1084 - accuracy: 0.9608 - val_loss: 0.1091 - val_accuracy: 0.9610\n",
      "Epoch 25/40\n",
      "427/427 [==============================] - 620s 1s/step - loss: 0.1039 - accuracy: 0.9631 - val_loss: 0.1273 - val_accuracy: 0.9554\n",
      "Epoch 26/40\n",
      "427/427 [==============================] - 620s 1s/step - loss: 0.0981 - accuracy: 0.9660 - val_loss: 0.1086 - val_accuracy: 0.9631\n",
      "Epoch 27/40\n",
      "427/427 [==============================] - 625s 1s/step - loss: 0.0947 - accuracy: 0.9683 - val_loss: 0.1694 - val_accuracy: 0.9358\n",
      "Epoch 28/40\n",
      "164/427 [==========>...................] - ETA: 5:22 - loss: 0.0968 - accuracy: 0.9651"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "427/427 [==============================] - 623s 1s/step - loss: 0.0918 - accuracy: 0.9672 - val_loss: 0.1587 - val_accuracy: 0.9370\n",
      "Epoch 30/40\n",
      "427/427 [==============================] - 621s 1s/step - loss: 0.0931 - accuracy: 0.9684 - val_loss: 0.1148 - val_accuracy: 0.9578\n",
      "Epoch 31/40\n",
      "427/427 [==============================] - 620s 1s/step - loss: 0.0830 - accuracy: 0.9707 - val_loss: 0.1092 - val_accuracy: 0.9645\n",
      "Epoch 32/40\n",
      "427/427 [==============================] - 620s 1s/step - loss: 0.0843 - accuracy: 0.9721 - val_loss: 0.1292 - val_accuracy: 0.9569\n",
      "Epoch 33/40\n",
      "427/427 [==============================] - 617s 1s/step - loss: 0.0794 - accuracy: 0.9726 - val_loss: 0.1177 - val_accuracy: 0.9598\n",
      "Epoch 34/40\n",
      "427/427 [==============================] - 613s 1s/step - loss: 0.0777 - accuracy: 0.9733 - val_loss: 0.1176 - val_accuracy: 0.9592\n",
      "Epoch 35/40\n",
      "427/427 [==============================] - 612s 1s/step - loss: 0.0765 - accuracy: 0.9741 - val_loss: 0.1011 - val_accuracy: 0.9634\n",
      "Epoch 36/40\n",
      "427/427 [==============================] - 612s 1s/step - loss: 0.0824 - accuracy: 0.9733 - val_loss: 0.0921 - val_accuracy: 0.9672\n",
      "Epoch 37/40\n",
      "427/427 [==============================] - 615s 1s/step - loss: 0.0709 - accuracy: 0.9754 - val_loss: 0.1974 - val_accuracy: 0.9302\n",
      "Epoch 38/40\n",
      "427/427 [==============================] - 617s 1s/step - loss: 0.0749 - accuracy: 0.9749 - val_loss: 0.0983 - val_accuracy: 0.9663\n",
      "Epoch 39/40\n",
      "427/427 [==============================] - 632s 1s/step - loss: 0.0785 - accuracy: 0.9733 - val_loss: 0.1052 - val_accuracy: 0.9639\n",
      "Epoch 40/40\n",
      "427/427 [==============================] - 612s 1s/step - loss: 0.0645 - accuracy: 0.9782 - val_loss: 0.1098 - val_accuracy: 0.9631\n"
     ]
    }
   ],
   "source": [
    "#create vgg16 model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (150, 150, 3)\n",
    "\n",
    "# Create a data augmentation block to apply on-the-fly transformations\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.1)\n",
    "])\n",
    "\n",
    "# Build the new model\n",
    "VGG_16 = models.Sequential()\n",
    "\n",
    "# Input layer and data augmentation\n",
    "VGG_16.add(layers.Input(shape=input_shape))\n",
    "VGG_16.add(data_augmentation)\n",
    "\n",
    "# Load the pre-trained VGG16 model (excluding the top classification layers)\n",
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "# Freeze all VGG16 layers initially\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Unfreeze the last few layers to allow fine-tuning for better feature adaptation\n",
    "for layer in vgg_model.layers[-4:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Add the VGG16 feature extractor to our model\n",
    "VGG_16.add(vgg_model)\n",
    "\n",
    "# Flatten the output from VGG16\n",
    "VGG_16.add(layers.Flatten())\n",
    "\n",
    "# Add improved fully-connected layers with batch normalization and dropout for regularization\n",
    "VGG_16.add(layers.Dense(128, activation='relu'))\n",
    "VGG_16.add(layers.BatchNormalization())\n",
    "VGG_16.add(layers.Dropout(0.5))\n",
    "VGG_16.add(layers.Dense(64, activation='relu'))\n",
    "VGG_16.add(layers.BatchNormalization())\n",
    "VGG_16.add(layers.Dropout(0.3))\n",
    "\n",
    "# Output layer for 2 classes (damage vs. no_damage) with softmax activation\n",
    "VGG_16.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model with a lower learning rate for fine-tuning\n",
    "VGG_16.compile(optimizer=optimizers.Adam(learning_rate=1e-5),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary to review the architecture\n",
    "VGG_16.summary()\n",
    "\n",
    "\n",
    "# fit the model from image generator\n",
    "history = VGG_16.fit(\n",
    "            train_rescale_ds,\n",
    "            batch_size=32,\n",
    "            epochs=40,\n",
    "            validation_data=val_rescale_ds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ae1d8c2-bec6-492d-9256-ccb13c7f9af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on test: 0.09198959916830063\n",
      "Accuracy on test: 0.9688159227371216\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = VGG_16.evaluate(test_rescale_ds, verbose=0)\n",
    "print(f\"Loss on test: {test_loss}\")\n",
    "print(f\"Accuracy on test: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62de4a9d-3e1b-4207-862b-b499cbb36c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save best model\n",
    "VGG_16.save(\"best.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ab3625-7e83-4c57-b1a7-090e33920830",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
