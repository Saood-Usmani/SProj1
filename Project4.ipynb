{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8091a3a1-c5e3-4953-a4e8-3ad8a985fc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/site-packages (from scikit-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers in /usr/local/lib/python3.12/site-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.12/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: joblib in /usr/local/lib/python3.12/site-packages (1.4.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#Cell 1: install requirements\n",
    "!pip install scikit-learn\n",
    "!pip install --upgrade transformers\n",
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b17a8faa-261f-464b-87bd-56d4dd9138a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 00:21:56.044770: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746404516.068844    2494 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746404516.076072    2494 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746404516.101834    2494 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746404516.101855    2494 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746404516.101857    2494 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746404516.101860    2494 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-05 00:21:56.109978: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import joblib\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from transformers import (\n",
    "    DistilBertTokenizerFast,\n",
    "    DistilBertForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc67f95d-6109-4dcb-b19e-8a576aaa6914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport pandas as pd\\nimport hashlib\\n\\n\\ndef anonymize_donor_names(input_csv: str, output_csv: str) -> pd.DataFrame:\\n    Load the transaction CSV, hash the Donor Name field using SHA-256,\\n    and write out a new CSV with names anonymized.\\n\\n    Parameters:\\n    -----------\\n    input_csv : str\\n        Path to your original CSV file.\\n    output_csv : str\\n        Path where the anonymized CSV will be saved.\\n\\n    Returns:\\n    --------\\n    pd.DataFrame\\n        The DataFrame with the \\'Donor Name\\' column replaced by its hash.\\n    # 1. Load\\n    df = pd.read_csv(input_csv)\\n\\n    # 2. Check for the column\\n    if \"Donor Name\" not in df.columns:\\n        raise KeyError(\"Could not find column \\'Donor Name\\' in the input CSV.\")\\n\\n    # 3. Hash each name (empty→hash of empty string)\\n    salt = \"hidden\"\\n    df[\"Donor Name\"] = (\\n        df[\"Donor Name\"]\\n        .fillna(\"\")\\n        .apply(lambda x: hashlib.sha256((salt + x).encode(\"utf-8\")).hexdigest())\\n    )\\n    # Replace memo field for ACCT_XFER rows based on description\\n    df.loc[\\n        (df[\"Type\"] == \"ACCT_XFER\")\\n        & (df[\"Description\"].str.startswith(\"Online Transfer from CHK ...hidden\")),\\n        \"Memo\",\\n    ] = \"Sadaqah - Masjid Operations\"\\n    df.loc[\\n        (df[\"Type\"] == \"ACCT_XFER\")\\n        & (df[\"Description\"].str.startswith(\"Online Transfer to CHK ...hidden\")),\\n        \"Memo\",\\n    ] = \"Ramadan\"\\n    df.loc[\\n        (df[\"Type\"] == \"ACCT_XFER\")\\n        & (df[\"Description\"].str.startswith(\"Online Transfer to CHK ...hidden\")),\\n        \"Memo\",\\n    ] = \"Reconstruction\"\\n    df.loc[\\n        (df[\"Type\"] == \"ACCT_XFER\")\\n        & (df[\"Description\"].str.startswith(\"Online Transfer to CHK ...hidden\")),\\n        \"Memo\",\\n    ] = \"Sadaqah - For Needy\"\\n    df.loc[\\n        (df[\"Type\"] == \"ACCT_XFER\")\\n        & (df[\"Description\"].str.startswith(\"Online Transfer to CHK ...hidden\")),\\n        \"Memo\",\\n    ] = \"Seminary\"\\n    df.loc[\\n        (df[\"Type\"] == \"ACCT_XFER\")\\n        & (df[\"Description\"].str.startswith(\"Online Transfer to CHK ...hidden\")),\\n        \"Memo\",\\n    ] = \"Zakat\"\\n    df.drop(\\n        columns=[\\n            \"Posting Date\",\\n            \"Description\",\\n            \"Balance\",\\n            \"ReferenceID\",\\n            \"Donation Date\",\\n            \"Email\",\\n            \"Source\",\\n            \"Unnamed: 13\",\\n            \"Sadaqah - Masjid Operations\",\\n            \"Sadaqah - For Needy\",\\n            \"Zakat\",\\n            \"Ramadan\",\\n            \"Reconstruction\",\\n            \"Seminary\",\\n            \"Unnamed: 20\",\\n            \"Diff\",\\n            \"Unnamed: 22\",\\n            \"Notes\",\\n        ],\\n        inplace=True,\\n    )\\n\\n    # Remove rows where \\'Details\\' column equals \\'TOTAL\\'\\n    df = df[df[\"Details\"] != \"TOTAL\"]\\n\\n    # Drop rows where Fund is missing or lists multiple accounts\\n    df = df[df[\"Fund\"].notna()]\\n    df = df[~df[\"Fund\"].str.contains(\",\")]\\n    # 4. Save anonymized CSV\\n    df.to_csv(output_csv, index=False)\\n    return df\\n\\n\\ndf_anon = anonymize_donor_names(\\n    \"ai/Miscellaneous Account Cleanup - Sheet1.csv\",\\n    \"ai/Miscellaneous Account Cleanup - Sheet1_anon.csv\",\\n)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 3: data preprocessing. This was done locally to protect sensitive information, more info in report\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "\n",
    "\n",
    "def anonymize_donor_names(input_csv: str, output_csv: str) -> pd.DataFrame:\n",
    "    Load the transaction CSV, hash the Donor Name field using SHA-256,\n",
    "    and write out a new CSV with names anonymized.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_csv : str\n",
    "        Path to your original CSV file.\n",
    "    output_csv : str\n",
    "        Path where the anonymized CSV will be saved.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        The DataFrame with the 'Donor Name' column replaced by its hash.\n",
    "    # 1. Load\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    # 2. Check for the column\n",
    "    if \"Donor Name\" not in df.columns:\n",
    "        raise KeyError(\"Could not find column 'Donor Name' in the input CSV.\")\n",
    "\n",
    "    # 3. Hash each name (empty→hash of empty string)\n",
    "    salt = \"hidden\"\n",
    "    df[\"Donor Name\"] = (\n",
    "        df[\"Donor Name\"]\n",
    "        .fillna(\"\")\n",
    "        .apply(lambda x: hashlib.sha256((salt + x).encode(\"utf-8\")).hexdigest())\n",
    "    )\n",
    "    # Replace memo field for ACCT_XFER rows based on description\n",
    "    df.loc[\n",
    "        (df[\"Type\"] == \"ACCT_XFER\")\n",
    "        & (df[\"Description\"].str.startswith(\"Online Transfer from CHK ...hidden\")),\n",
    "        \"Memo\",\n",
    "    ] = \"Sadaqah - Masjid Operations\"\n",
    "    df.loc[\n",
    "        (df[\"Type\"] == \"ACCT_XFER\")\n",
    "        & (df[\"Description\"].str.startswith(\"Online Transfer to CHK ...hidden\")),\n",
    "        \"Memo\",\n",
    "    ] = \"Ramadan\"\n",
    "    df.loc[\n",
    "        (df[\"Type\"] == \"ACCT_XFER\")\n",
    "        & (df[\"Description\"].str.startswith(\"Online Transfer to CHK ...hidden\")),\n",
    "        \"Memo\",\n",
    "    ] = \"Reconstruction\"\n",
    "    df.loc[\n",
    "        (df[\"Type\"] == \"ACCT_XFER\")\n",
    "        & (df[\"Description\"].str.startswith(\"Online Transfer to CHK ...hidden\")),\n",
    "        \"Memo\",\n",
    "    ] = \"Sadaqah - For Needy\"\n",
    "    df.loc[\n",
    "        (df[\"Type\"] == \"ACCT_XFER\")\n",
    "        & (df[\"Description\"].str.startswith(\"Online Transfer to CHK ...hidden\")),\n",
    "        \"Memo\",\n",
    "    ] = \"Seminary\"\n",
    "    df.loc[\n",
    "        (df[\"Type\"] == \"ACCT_XFER\")\n",
    "        & (df[\"Description\"].str.startswith(\"Online Transfer to CHK ...hidden\")),\n",
    "        \"Memo\",\n",
    "    ] = \"Zakat\"\n",
    "    df.drop(\n",
    "        columns=[\n",
    "            \"Posting Date\",\n",
    "            \"Description\",\n",
    "            \"Balance\",\n",
    "            \"ReferenceID\",\n",
    "            \"Donation Date\",\n",
    "            \"Email\",\n",
    "            \"Source\",\n",
    "            \"Unnamed: 13\",\n",
    "            \"Sadaqah - Masjid Operations\",\n",
    "            \"Sadaqah - For Needy\",\n",
    "            \"Zakat\",\n",
    "            \"Ramadan\",\n",
    "            \"Reconstruction\",\n",
    "            \"Seminary\",\n",
    "            \"Unnamed: 20\",\n",
    "            \"Diff\",\n",
    "            \"Unnamed: 22\",\n",
    "            \"Notes\",\n",
    "        ],\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    # Remove rows where 'Details' column equals 'TOTAL'\n",
    "    df = df[df[\"Details\"] != \"TOTAL\"]\n",
    "\n",
    "    # Drop rows where Fund is missing or lists multiple accounts\n",
    "    df = df[df[\"Fund\"].notna()]\n",
    "    df = df[~df[\"Fund\"].str.contains(\",\")]\n",
    "    # 4. Save anonymized CSV\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "df_anon = anonymize_donor_names(\n",
    "    \"ai/Miscellaneous Account Cleanup - Sheet1.csv\",\n",
    "    \"ai/Miscellaneous Account Cleanup - Sheet1_anon.csv\",\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59e1ed80-a2d2-4194-9085-7a4409feeb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 3.5: read csv from disk \n",
    "df = pd.read_csv(\"Miscellaneous Account Cleanup - Sheet1_anon.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "246388ee-c5a7-41b7-8109-f8f70c46f888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Details</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Type</th>\n",
       "      <th>Donor Name</th>\n",
       "      <th>Fund</th>\n",
       "      <th>Memo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CREDIT</td>\n",
       "      <td>1.00</td>\n",
       "      <td>ACCT_XFER</td>\n",
       "      <td>797e1bca657d149611fc11d26e6a60fd62798b6095897a...</td>\n",
       "      <td>Sadaqah - Masjid Operations</td>\n",
       "      <td>Sadaqah - Masjid Operations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CREDIT</td>\n",
       "      <td>11.11</td>\n",
       "      <td>PARTNERFI_TO_CHASE</td>\n",
       "      <td>7a5d7ecbb7a12468b1cbdeeeaf5127f03d2377578cd67f...</td>\n",
       "      <td>Sadaqah - For Needy</td>\n",
       "      <td>Sadaqa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CREDIT</td>\n",
       "      <td>2.00</td>\n",
       "      <td>PARTNERFI_TO_CHASE</td>\n",
       "      <td>d4cc3604dd422d3f342b7c2474a2d00aebff74051d3ff6...</td>\n",
       "      <td>Sadaqah - Masjid Operations</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CREDIT</td>\n",
       "      <td>5.00</td>\n",
       "      <td>QUICKPAY_CREDIT</td>\n",
       "      <td>61ac16b23d67abb8f0a6804ccc03da15b83e069f17b629...</td>\n",
       "      <td>Sadaqah - Masjid Operations</td>\n",
       "      <td>pakistan food relief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CREDIT</td>\n",
       "      <td>10.00</td>\n",
       "      <td>QUICKPAY_CREDIT</td>\n",
       "      <td>e617589ec529bc7f6b494818887779160493eb08b7102e...</td>\n",
       "      <td>Sadaqah - Masjid Operations</td>\n",
       "      <td>flood relief</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Details  Amount                Type  \\\n",
       "0  CREDIT    1.00           ACCT_XFER   \n",
       "1  CREDIT   11.11  PARTNERFI_TO_CHASE   \n",
       "2  CREDIT    2.00  PARTNERFI_TO_CHASE   \n",
       "3  CREDIT    5.00     QUICKPAY_CREDIT   \n",
       "4  CREDIT   10.00     QUICKPAY_CREDIT   \n",
       "\n",
       "                                          Donor Name  \\\n",
       "0  797e1bca657d149611fc11d26e6a60fd62798b6095897a...   \n",
       "1  7a5d7ecbb7a12468b1cbdeeeaf5127f03d2377578cd67f...   \n",
       "2  d4cc3604dd422d3f342b7c2474a2d00aebff74051d3ff6...   \n",
       "3  61ac16b23d67abb8f0a6804ccc03da15b83e069f17b629...   \n",
       "4  e617589ec529bc7f6b494818887779160493eb08b7102e...   \n",
       "\n",
       "                          Fund                         Memo  \n",
       "0  Sadaqah - Masjid Operations  Sadaqah - Masjid Operations  \n",
       "1          Sadaqah - For Needy                       Sadaqa  \n",
       "2  Sadaqah - Masjid Operations                          NaN  \n",
       "3  Sadaqah - Masjid Operations         pakistan food relief  \n",
       "4  Sadaqah - Masjid Operations                 flood relief  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc3dafe5-3527-483f-b230-18f19e2e0df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Build the text input from the five fields + amount token\n",
    "df[[\"Details\",\"Type\",\"Donor Name\",\"Memo\"]] = (\n",
    "    df[[\"Details\",\"Type\",\"Donor Name\",\"Memo\"]]\n",
    "      .fillna(\"\")\n",
    "      .astype(str)\n",
    "      .map(str.lower)\n",
    ")\n",
    "df[\"Amount\"] = df[\"Amount\"].astype(float)\n",
    "\n",
    "df[\"text\"] = (\n",
    "    df[\"Details\"] + \" | \"\n",
    "  + df[\"Type\"]    + \" | \"\n",
    "  + df[\"Donor Name\"] + \" | \"\n",
    "  + df[\"Memo\"]    + \" | \"\n",
    "  + df[\"Amount\"].apply(lambda x: f\"<amt={x:.2f}>\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f815b51-58ba-4dde-ba9b-b7c061dfe291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes: 2230 train, 478 val, 478 test\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Label‐encode the Fund target and stratify‐split\n",
    "le = LabelEncoder().fit(df[\"Fund\"])\n",
    "df[\"label\"] = le.transform(df[\"Fund\"])\n",
    "\n",
    "train_df, temp_df = train_test_split(\n",
    "    df, test_size=0.30, stratify=df[\"label\"], random_state=42\n",
    ")\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df, test_size=0.50, stratify=temp_df[\"label\"], random_state=42\n",
    ")\n",
    "\n",
    "print(\"Sizes:\", len(train_df), \"train,\", len(val_df), \"val,\", len(test_df), \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a96e0156-1901-4226-8a8d-151e5eef09d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ train/examples: 2230, val: 478, test: 478\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Manual tokenization → TensorDataset (avoids Arrow copy-error)\n",
    "\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# 1. Tokenize in one go\n",
    "train_enc = tokenizer(\n",
    "    train_df[\"text\"].tolist(),\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=256,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "val_enc = tokenizer(\n",
    "    val_df[\"text\"].tolist(),\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=256,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "test_enc = tokenizer(\n",
    "    test_df[\"text\"].tolist(),\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=256,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# 2. Build TensorDatasets\n",
    "train_dataset = TensorDataset(\n",
    "    train_enc.input_ids,\n",
    "    train_enc.attention_mask,\n",
    "    torch.tensor(train_df[\"label\"].values, dtype=torch.long),\n",
    ")\n",
    "val_dataset = TensorDataset(\n",
    "    val_enc.input_ids,\n",
    "    val_enc.attention_mask,\n",
    "    torch.tensor(val_df[\"label\"].values, dtype=torch.long),\n",
    ")\n",
    "test_dataset = TensorDataset(\n",
    "    test_enc.input_ids,\n",
    "    test_enc.attention_mask,\n",
    "    torch.tensor(test_df[\"label\"].values, dtype=torch.long),\n",
    ")\n",
    "\n",
    "print(f\"→ train/examples: {len(train_dataset)}, val: {len(val_dataset)}, test: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c52dbff3-6080-430e-b187-0ecd016cea5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21000' max='21000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21000/21000 17:10:06, Epoch 150/150]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.193515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.127812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.121715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.247200</td>\n",
       "      <td>0.131757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.247200</td>\n",
       "      <td>0.124959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.247200</td>\n",
       "      <td>0.158625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.247200</td>\n",
       "      <td>0.104948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.056700</td>\n",
       "      <td>0.120336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.056700</td>\n",
       "      <td>0.205323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.056700</td>\n",
       "      <td>0.105623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.036800</td>\n",
       "      <td>0.130006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.036800</td>\n",
       "      <td>0.111879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.036800</td>\n",
       "      <td>0.104747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.036800</td>\n",
       "      <td>0.116257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>0.118031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>0.148344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>0.155185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.150012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.164632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.154365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.146341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>0.132222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>0.136069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>0.142975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.163419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.169082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.163541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.161986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>0.173397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>0.173038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>0.174995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>0.178915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.169066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.173364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.189591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.194289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.262678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.236232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.225070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.185113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.187041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.189405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.187812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.229075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.200558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.198643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.199921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.476775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.191766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>0.210917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>0.171829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>0.257023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>0.214836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.272921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.187147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.228469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.180188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.233013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.234175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.219182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.210156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.213803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.219524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.221475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.231654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.212238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.212267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.283324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.284653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.282446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.284118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.284988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.247026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.249575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.247283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.249576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.249209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.252891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.252512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.255440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.261549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.260263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.262885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.263988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.267430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.268218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.303279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.266669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.241304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.207372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.186920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.233914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.206992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.234716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.233542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.214921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.218454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.219395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.221476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.223141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.224132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.225342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.226836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.229859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.231535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.232662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.231993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.231635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.234157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.234748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.239206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.238312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.240318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.242241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.242712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.242819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.243204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.243600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.244368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.247282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.245574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.245848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.248932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.247191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.248887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.248866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.248076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.248924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.249615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.250343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.250718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.252037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.252080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.252190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.252167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.252826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.253093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.253533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.250332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.247796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.250812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.248981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.248364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.248435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.248830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.249135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.249432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.249616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.249704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.249726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=21000, training_loss=0.012422518202236721, metrics={'train_runtime': 61810.6483, 'train_samples_per_second': 5.412, 'train_steps_per_second': 0.34, 'total_flos': 2.2156752849408e+16, 'train_loss': 0.012422518202236721, 'epoch': 150.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cell 7: fine tune\n",
    "num_labels = len(le.classes_)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=num_labels,\n",
    "    problem_type=\"single_label_classification\"\n",
    ")\n",
    "\n",
    "def tuple_collator(batch):\n",
    "    input_ids      = torch.stack([item[0] for item in batch])\n",
    "    attention_mask = torch.stack([item[1] for item in batch])\n",
    "    labels         = torch.tensor([item[2] for item in batch], dtype=torch.long)\n",
    "    return {\n",
    "        \"input_ids\":      input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\":         labels,\n",
    "    }\n",
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=150,\n",
    "    per_device_train_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "\n",
    "    save_strategy=\"epoch\",            \n",
    "    save_total_limit=1,               \n",
    "    load_best_model_at_end=True,      \n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,         \n",
    "\n",
    "    eval_strategy=\"epoch\",\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,   # this is your TensorDataset\n",
    "    eval_dataset=val_dataset,      # same here\n",
    "    data_collator=tuple_collator,  # <- override the default\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1787941-2cb3-403c-9255-4aaab77ff681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             precision    recall  f1-score   support\n",
      "\n",
      "                    Ramadan       0.98      0.98      0.98        57\n",
      "             Reconstruction       0.92      0.88      0.90        50\n",
      "        Sadaqah - For Needy       0.85      0.89      0.87        19\n",
      "Sadaqah - Masjid Operations       0.99      0.99      0.99       326\n",
      "                   Seminary       1.00      1.00      1.00         5\n",
      "                      Zakat       0.91      0.95      0.93        21\n",
      "\n",
      "                   accuracy                           0.97       478\n",
      "                  macro avg       0.94      0.95      0.95       478\n",
      "               weighted avg       0.97      0.97      0.97       478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Evaluate on test set\n",
    "preds = trainer.predict(test_dataset)\n",
    "y_pred = np.argmax(preds.predictions, axis=1)\n",
    "y_true = test_df[\"label\"]\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e55b633b-77f7-47cd-9319-6e76d74f3610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fund_model/best/label_encoder.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 9: Save model\n",
    "model.save_pretrained(\"fund_model/best/\")\n",
    "tokenizer.save_pretrained(\"fund_model/best/\")\n",
    "joblib.dump(le, \"fund_model/best/label_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815b4fba-e7fd-4e0d-b104-de3680356aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
